{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VoiceShield.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ID3hGc81Td3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Logo](http://gdurl.com/50kR \"VoiceShield\")\n",
        "\n",
        "# VoiceShield"
      ]
    },
    {
      "metadata": {
        "id": "Ph-kXM1EqxXS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up environment"
      ]
    },
    {
      "metadata": {
        "id": "ZMuuInNfnmcC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ]
    },
    {
      "metadata": {
        "id": "wErhGO8PeqQ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import PIL as pil\n",
        "import skimage\n",
        "import numpy as np\n",
        "import torch as torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k6HN1RexnmcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set pyplot mode"
      ]
    },
    {
      "metadata": {
        "id": "dfAqFGL-nmcK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4Rn25epnmcO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set random seed (for repeatability)"
      ]
    },
    {
      "metadata": {
        "id": "PuVWsTzprT9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 16\n",
        "random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IaP4gAFZnmcS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're doing this on a GPU. Modify if you want to try on a CPU, etc."
      ]
    },
    {
      "metadata": {
        "id": "z2JBeIygp02u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jTed244TbeK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get data"
      ]
    },
    {
      "metadata": {
        "id": "mPznrpYznmcY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download and extract speaker-labelled dataset"
      ]
    },
    {
      "metadata": {
        "id": "FQ4VflMwdERM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if \"spoken_numbers_wav.tar\" not in os.listdir():\n",
        "    !wget \"http://pannous.net/files/spoken_numbers_wav.tar\"\n",
        "    !tar -xf spoken_numbers_wav.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENr4cUEunmcc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get filenames"
      ]
    },
    {
      "metadata": {
        "id": "v34bR0VHr5aQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"spoken_numbers_wav\")\n",
        "filenames = os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lqI8stT5nmcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Buckets for data"
      ]
    },
    {
      "metadata": {
        "id": "VHNQfQkNu2fi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainA = []\n",
        "testA = []\n",
        "trainB = []\n",
        "testB = []\n",
        "\n",
        "trainA_labels = []\n",
        "testA_labels = []\n",
        "trainB_labels = []\n",
        "testB_labels = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIv8JHKSLGQQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Populate 'data buckets' from spectrogram files\n",
        "\n",
        "Note: If this fails due to an AttributeError (making angry noises about PIL.Image), it's due to a bug caused by re-importing a different version of PIL than the default. Restart the runtime and re-run everything (except the filesystem stuff, which should carry over unless the whole environment is reset)."
      ]
    },
    {
      "metadata": {
        "id": "f85Qd3ePs3wc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for f in filenames:\n",
        "  if f[-4:] == \".png\" and \"_100.\" in f:\n",
        "    img = pil.Image.open(f)\n",
        "    img = img.resize((256, 256), pil.Image.LANCZOS)\n",
        "    data = torchvision.transforms.ToTensor()(img)\n",
        "    for i in range(7):\n",
        "      r = random.randint(0, 4)\n",
        "      if \"Alex\" in f:\n",
        "        dataset = testA if r == 0 else trainA\n",
        "        labelset = testA_labels if r == 0 else trainA_labels\n",
        "      elif \"Tom\" in f:\n",
        "        dataset = testB if r == 0 else trainB\n",
        "        labelset = testB_labels if r == 0 else trainB_labels\n",
        "      else:\n",
        "        continue\n",
        "      if i == 0:\n",
        "        dataset.append(data)\n",
        "      elif i == 1:\n",
        "        dataset.append(torch.FloatTensor(skimage.util.random_noise(data, mode = \"gaussian\", seed = seed)))\n",
        "      elif i == 2:\n",
        "        dataset.append(torch.FloatTensor(skimage.util.random_noise(data, mode = \"poisson\", seed = seed)))\n",
        "      elif i == 3:\n",
        "        dataset.append(torch.FloatTensor(skimage.util.random_noise(data, mode = \"salt\", seed = seed)))\n",
        "      elif i == 4:\n",
        "        dataset.append(torch.FloatTensor(skimage.util.random_noise(data, mode = \"pepper\", seed = seed)))\n",
        "      elif i == 5:\n",
        "        dataset.append(torch.FloatTensor(skimage.util.random_noise(data, mode = \"s&p\", seed = seed)))\n",
        "      elif i == 6:\n",
        "        dataset.append(torch.FloatTensor(skimage.util.random_noise(data, mode = \"speckle\", seed = seed)))\n",
        "      label = torch.zeros(10)\n",
        "      label[int(f.split('_')[0])] = 1\n",
        "      labelset.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tfOUbAdhnmco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create Pytorch structures for loading data"
      ]
    },
    {
      "metadata": {
        "id": "ljNRNoPA2GV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainA = torch.stack(trainA)\n",
        "testA = torch.stack(testA)\n",
        "trainB = torch.stack(trainB)\n",
        "testB = torch.stack(testB)\n",
        "\n",
        "trainA_labels = torch.stack(trainA_labels).long()\n",
        "testA_labels = torch.stack(testA_labels).long()\n",
        "trainB_labels = torch.stack(trainB_labels).long()\n",
        "testB_labels = torch.stack(testB_labels).long()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IzKXdYRnnmcs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainsetA = torch.utils.data.TensorDataset(trainA, trainA_labels)\n",
        "testsetA = torch.utils.data.TensorDataset(testA, testA_labels)\n",
        "trainsetB = torch.utils.data.TensorDataset(trainB, trainB_labels)\n",
        "testsetB = torch.utils.data.TensorDataset(testB, testB_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zu__khKbB-JA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hyp_miniBatchSize = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4oCV-n2-nmcy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainloaderA = torch.utils.data.DataLoader(dataset=trainsetA, batch_size=hyp_miniBatchSize, shuffle=True)\n",
        "testloaderA = torch.utils.data.DataLoader(dataset=testsetA, batch_size=hyp_miniBatchSize, shuffle=False)\n",
        "trainloaderB = torch.utils.data.DataLoader(dataset=trainsetB, batch_size=hyp_miniBatchSize, shuffle=True)\n",
        "testloaderB = torch.utils.data.DataLoader(dataset=testsetB, batch_size=hyp_miniBatchSize, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9iQgYMOnmc0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create uniform mini-batches for discriminators"
      ]
    },
    {
      "metadata": {
        "id": "j-WkNmrxnmc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(hyp_miniBatchSize)[None, :].to(\"cuda\")\n",
        "ones = torch.ones(hyp_miniBatchSize)[None, :].to(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w6W7tZz4TgNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create models"
      ]
    },
    {
      "metadata": {
        "id": "AsgzX2XInmc-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Residual block: convolutional layers with a manual identity at the end, allowing easy learning of the identity function for extra parameters"
      ]
    },
    {
      "metadata": {
        "id": "CXtfHGiRz9Ck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ResidualBlock(torch.nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    \n",
        "    # Create list of layer functions\n",
        "    layers = []\n",
        "    \n",
        "    # Add the first set of layers (convolution and wrappers)\n",
        "    layers.append(torch.nn.ReflectionPad2d(1))\n",
        "    layers.append(torch.nn.Conv2d(size, size, kernel_size = 3, padding = 0, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(size))\n",
        "    layers.append(torch.nn.ReLU(True))\n",
        "    \n",
        "    # Add the second set of layers\n",
        "    layers.append(torch.nn.ReflectionPad2d(1))\n",
        "    layers.append(torch.nn.Conv2d(size, size, kernel_size = 3, padding = 0, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(size))\n",
        "    \n",
        "    # Create the model\n",
        "    self.resBlock = torch.nn.Sequential(*layers)\n",
        "  def forward(self, x):\n",
        "    # Pass input through all layers\n",
        "    # Add x, to promote identity learning\n",
        "    return self.resBlock(x) + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g3XSwuaInmdC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generator: neural network models using convolutional downsampling, residual blocks, and upsampling to generate modified data based on an input. Used to create fake data via perturbations on the real manifold."
      ]
    },
    {
      "metadata": {
        "id": "fXybFOQd2hW8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(torch.nn.Module):\n",
        "  def __init__(self, input_shape, num_resBlocks=9): # input_shape should be (minibatch_size, num_channels, height, width)\n",
        "    super(Generator, self).__init__()\n",
        "    \n",
        "    # Create list of layer functions\n",
        "    layers = []\n",
        "    \n",
        "    # Add initial convolution\n",
        "    layers.append(torch.nn.ReflectionPad2d(3))\n",
        "    layers.append(torch.nn.Conv2d(input_shape[1], 64, kernel_size = 7, padding = 0, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(64))\n",
        "    layers.append(torch.nn.ReLU(True))\n",
        "    \n",
        "    # Add first downsampling\n",
        "    layers.append(torch.nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(128))\n",
        "    layers.append(torch.nn.ReLU(True))\n",
        "    \n",
        "    # Add second downsampling\n",
        "    layers.append(torch.nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(256))\n",
        "    layers.append(torch.nn.ReLU(True))\n",
        "    \n",
        "    # Add residual blocks\n",
        "    for i in range(num_resBlocks):\n",
        "      layers.append(ResidualBlock(256))\n",
        "    \n",
        "    # Add first upsampling\n",
        "    layers.append(torch.nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 2, padding = 1, output_padding = 1, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(128))\n",
        "    layers.append(torch.nn.ReLU(True))\n",
        "    \n",
        "    # Add second upsampling\n",
        "    layers.append(torch.nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 2, padding = 1, output_padding = 1, bias = True))\n",
        "    layers.append(torch.nn.InstanceNorm2d(64))\n",
        "    layers.append(torch.nn.ReLU(True))\n",
        "    \n",
        "    # Add final convolution\n",
        "    layers.append(torch.nn.ReflectionPad2d(3))\n",
        "    layers.append(torch.nn.Conv2d(64, input_shape[1], kernel_size = 7, padding = 0))\n",
        "    layers.append(torch.nn.Tanh())\n",
        "    \n",
        "    # Create the model\n",
        "    self.generator = torch.nn.Sequential(*layers)\n",
        "  def forward(self, x):\n",
        "    # Pass input through all layers to reach output\n",
        "    return self.generator(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQDu-QixnmdG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Discriminator: neural network models using convolution and residual blocks to classify an input into one of a number of categories. Used to classify voice data, both by what is spoken ('C' networks) and by who the speaker is ('D' networks)."
      ]
    },
    {
      "metadata": {
        "id": "Df6oirIm0TFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "  def __init__(self, input_shape, num_layers=3, num_outputs=1, use_residual=False):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    # Create list of layer functions\n",
        "    layers = []\n",
        "    \n",
        "    # Add initial convolution\n",
        "    layers.append(torch.nn.Conv2d(input_shape[1], 64, kernel_size = 4, stride = 2, padding = 1))\n",
        "    layers.append(torch.nn.LeakyReLU(0.2, True))\n",
        "    \n",
        "    if use_residual:\n",
        "      # Add growing residual blocks\n",
        "      for i in range(1, num_layers + 1):\n",
        "        layers.append(ResidualBlock(64 * min(2 ** (i - 1), 8)))\n",
        "        layers.append(torch.nn.Conv2d(64 * min(2 ** (i - 1), 8), 64 * min(2 ** i, 8), kernel_size = 4, stride = (1 if i == num_layers else 2), padding = 1, bias = True))\n",
        "    else:\n",
        "      # Add growing convolutional layers\n",
        "      scale = 1\n",
        "      for i in range(1, num_layers + 1):\n",
        "        scaleOld = scale\n",
        "        scale = min(2 ** i, 8)\n",
        "        layers.append(torch.nn.Conv2d(64 * scaleOld, 64 * scale, kernel_size = 4, stride = (1 if i == num_layers else 2), padding = 1, bias = True))\n",
        "        layers.append(torch.nn.InstanceNorm2d(64 * scale))\n",
        "        layers.append(torch.nn.LeakyReLU(0.2, True))\n",
        "    \n",
        "    # Add final convolution\n",
        "    layers.append(torch.nn.Conv2d(64 * min(2 ** num_layers, 8), 32, kernel_size = 4, stride = 1, padding = 1))\n",
        "    \n",
        "    # Add final layers (reshaping for output)\n",
        "    finalLayers = []\n",
        "    finalLayers.append(torch.nn.Linear((2 ** (7 - min(num_layers, 6)) - 1) ** 2 * 128, num_outputs))\n",
        "    finalLayers.append(torch.nn.Softmax(1))\n",
        "    \n",
        "    # Create the model\n",
        "    self.num_layers = num_layers\n",
        "    self.discriminator = torch.nn.Sequential(*layers)\n",
        "    self.finalLayers = torch.nn.Sequential(*finalLayers)\n",
        "  def forward(self, x):\n",
        "    # Pass input through all layers\n",
        "    # Reshape to classes\n",
        "    return self.finalLayers(self.discriminator(x).view(-1, (2 ** (7 - min(self.num_layers, 6)) - 1) ** 2 * 128))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DYROecH2nmdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://)Create instances of models to train"
      ]
    },
    {
      "metadata": {
        "id": "f1xnh_ndBxEG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G_A = Generator((hyp_miniBatchSize,) + tuple(trainA.shape)[1:])\n",
        "G_B = Generator((hyp_miniBatchSize,) + tuple(trainB.shape)[1:])\n",
        "\n",
        "D_A = Discriminator((hyp_miniBatchSize,) + tuple(trainA.shape)[1:], num_layers=6, use_residual = True)\n",
        "D_B = Discriminator((hyp_miniBatchSize,) + tuple(trainB.shape)[1:], num_layers=6, use_residual = True)\n",
        "\n",
        "C_A = Discriminator((hyp_miniBatchSize,) + tuple(trainA.shape)[1:], num_layers=6, num_outputs = tuple(trainA_labels.shape)[1], use_residual = True)\n",
        "C_B = Discriminator((hyp_miniBatchSize,) + tuple(trainB.shape)[1:], num_layers=6, num_outputs = tuple(trainB_labels.shape)[1], use_residual = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GP_qV9bvnmdM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ]
    },
    {
      "metadata": {
        "id": "IHdDcC7VnmdO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set `voiceShield` to `True` to use my novel method, or `False` to use traditional training."
      ]
    },
    {
      "metadata": {
        "id": "IhawfFRWnmdO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "voiceShield = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWA4VKLgnmdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Whether or not to use identity loss function"
      ]
    },
    {
      "metadata": {
        "id": "2j_sHsk9nmdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idtLoss = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tG03dHlBnmdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Move models to GPU"
      ]
    },
    {
      "metadata": {
        "id": "Y76gwg4LEPDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G_A = G_A.to(\"cuda\")\n",
        "G_B = G_B.to(\"cuda\")\n",
        "D_A = D_A.to(\"cuda\")\n",
        "D_B = D_B.to(\"cuda\")\n",
        "C_A = C_A.to(\"cuda\")\n",
        "C_B = C_B.to(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HG9z30qpnmdY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Learning rate (configurable hyperparameter controlling rate of gradient descent)"
      ]
    },
    {
      "metadata": {
        "id": "EwbM25btnmdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hyp_learn_rate = 0.005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sasuS9bGnmdc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hyperparameter to weight cyclical and identity losses equally"
      ]
    },
    {
      "metadata": {
        "id": "kt1s7uPUnmdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hyp_lambda = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfLnXsXsnmde",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Epochs (full passes of training data) to train models"
      ]
    },
    {
      "metadata": {
        "id": "5vvL1DNfnmde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztfUOZ6Qnmdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create optimizers (algorithms to optimizer model parameters, varying on gradient descent)"
      ]
    },
    {
      "metadata": {
        "id": "iS1n1N5tnmdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_G_A = torch.optim.Adam(G_A.parameters(), lr=hyp_learn_rate)\n",
        "opt_G_B = torch.optim.Adam(G_B.parameters(), lr=hyp_learn_rate)\n",
        "opt_D_A = torch.optim.Adam(D_A.parameters(), lr=hyp_learn_rate)\n",
        "opt_D_B = torch.optim.Adam(D_B.parameters(), lr=hyp_learn_rate)\n",
        "opt_C_A = torch.optim.Adam(C_A.parameters(), lr=hyp_learn_rate)\n",
        "opt_C_B = torch.optim.Adam(C_B.parameters(), lr=hyp_learn_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wLxEldsHnmdi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Basic loss functions"
      ]
    },
    {
      "metadata": {
        "id": "mJjY3U39nmdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lossD = torch.nn.BCELoss()\n",
        "lossC = torch.nn.CrossEntropyLoss()\n",
        "lossCyc = torch.nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYOIxBBMnmdo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Method for training step on speaker A data"
      ]
    },
    {
      "metadata": {
        "id": "IWV8QG_Znmdo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainEpochA(epoch):\n",
        "    for i, (images, labels) in enumerate(trainloaderA):\n",
        "        # Transfer data to GPU\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        label = torch.max(labels, 1)[1]\n",
        "        \n",
        "        # Reset optimizers\n",
        "        opt_G_A.zero_grad()\n",
        "        opt_G_B.zero_grad()\n",
        "        opt_D_A.zero_grad()\n",
        "        opt_D_B.zero_grad()\n",
        "        opt_C_A.zero_grad()\n",
        "        opt_C_B.zero_grad()\n",
        "        \n",
        "        # Pass through generators\n",
        "        fake_B = G_B(images)\n",
        "        idt_A = G_A(images)\n",
        "        cyc_A = G_A(G_B(images))\n",
        "        cyc_B = G_B(G_A(images))\n",
        "        \n",
        "        # Compute losses\n",
        "        lossC_A = lossC(C_A(images), label)\n",
        "        lossD_A = lossD(D_A(images), ones)\n",
        "        if voiceShield:\n",
        "            lossD_B = lossD(D_B(images), zeros) + lossD(D_B(fake_B), zeros)\n",
        "        else:\n",
        "            lossD_B = lossD(D_B(images), zeros)\n",
        "        if idtLoss:\n",
        "            lossG_A = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images) + lossCyc(idt_A, images))\n",
        "        else:\n",
        "            lossG_A = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        lossG_B = lossD(D_B(fake_B), ones) + lossC(C_B(fake_B), label) + hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        \n",
        "        # Backpropagate (training step)\n",
        "        lossC_A.backward(retain_graph=True)\n",
        "        opt_C_A.step()\n",
        "        lossD_A.backward(retain_graph=True)\n",
        "        opt_D_A.step()\n",
        "        lossD_B.backward(retain_graph=True)\n",
        "        opt_D_B.step()\n",
        "        lossG_A.backward(retain_graph=True)\n",
        "        opt_G_A.step()\n",
        "        lossG_B.backward()\n",
        "        opt_G_B.step()\n",
        "        \n",
        "        # Print results\n",
        "        if (i + 1) % len(trainA) == 0:\n",
        "            print('Epoch [%d/%d], Step[%d/%d] (Train set A): LossC_A: %.6f, LossD_A: %.6f, LossD_B: %.6f, LossG_A: %.6f, LossG_B: %.6f, '\n",
        "              %(epoch + 1, num_epochs, i + 1, len(trainA)//hyp_miniBatchSize, lossC_A.item(), lossD_A.item(), lossD_B.item(), lossG_A.item(), lossG_B.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RSVHXsM2nmdo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Method for training step on speaker B data"
      ]
    },
    {
      "metadata": {
        "id": "YZu2HphYnmdq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainEpochB(epoch):\n",
        "    for i, (images, labels) in enumerate(trainloaderB):\n",
        "        # Transfer data to GPU\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        label = torch.max(labels, 1)[1]\n",
        "        \n",
        "        # Reset optimizers\n",
        "        opt_G_A.zero_grad()\n",
        "        opt_G_B.zero_grad()\n",
        "        opt_D_A.zero_grad()\n",
        "        opt_D_B.zero_grad()\n",
        "        opt_C_A.zero_grad()\n",
        "        opt_C_B.zero_grad()\n",
        "        \n",
        "        # Pass through generators\n",
        "        fake_A = G_A(images)\n",
        "        idt_B = G_B(images)\n",
        "        cyc_A = G_A(G_B(images))\n",
        "        cyc_B = G_B(G_A(images))\n",
        "        \n",
        "        # Compute losses\n",
        "        lossC_B = lossC(C_B(images), label)\n",
        "        lossD_B = lossD(D_B(images), ones)\n",
        "        if voiceShield:\n",
        "            lossD_A = lossD(D_A(images), zeros) + lossD(D_A(fake_A), zeros)\n",
        "        else:\n",
        "            lossD_A = lossD(D_A(images), zeros)\n",
        "        if idtLoss:\n",
        "            lossG_B = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images) + lossCyc(idt_B, images))\n",
        "        else:\n",
        "            lossG_B = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        lossG_A = lossD(D_A(fake_A), ones) + lossC(C_A(fake_A), label) + hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        \n",
        "        # Backpropagate (training step)\n",
        "        lossC_B.backward(retain_graph=True)\n",
        "        opt_C_B.step()\n",
        "        lossD_A.backward(retain_graph=True)\n",
        "        opt_D_A.step()\n",
        "        lossD_B.backward(retain_graph=True)\n",
        "        opt_D_B.step()\n",
        "        lossG_A.backward(retain_graph=True)\n",
        "        opt_G_A.step()\n",
        "        lossG_B.backward()\n",
        "        opt_G_B.step()\n",
        "        \n",
        "        # Print results\n",
        "        if (i + 1) % len(trainB) == 0:\n",
        "            print('Epoch [%d/%d], Step[%d/%d] (Train set B): LossC_B: %.6f, LossD_A: %.6f, LossD_B: %.6f, LossG_A: %.6f, LossG_B: %.6f, '\n",
        "             %(epoch + 1, num_epochs, i + 1, len(trainB)//hyp_miniBatchSize, lossC_B.item(), lossD_A.item(), lossD_B.item(), lossG_A.item(), lossG_B.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MngJnwAZnmds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Method for testing step (new data, no learning - for evaluation purposes) on speaker A data"
      ]
    },
    {
      "metadata": {
        "id": "QCfCh-BOnmds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def testEpochA(epoch):\n",
        "    correctD_A = 0\n",
        "    totalD_A = 0\n",
        "    correctD_B = 0\n",
        "    totalD_B = 0\n",
        "    correctC_A = 0\n",
        "    totalC_A = 0\n",
        "    for i, (images, labels) in enumerate(testloaderA):\n",
        "        # Transfer data to GPU\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        label = torch.max(labels, 1)[1]\n",
        "        \n",
        "        # Pass through generators\n",
        "        fake_B = G_B(images)\n",
        "        idt_A = G_A(images)\n",
        "        cyc_A = G_A(G_B(images))\n",
        "        cyc_B = G_B(G_A(images))\n",
        "        \n",
        "        # Compute losses\n",
        "        lossC_A = lossC(C_A(images), label)\n",
        "        lossD_A = lossD(D_A(images), ones)\n",
        "        if voiceShield:\n",
        "            lossD_B = lossD(D_B(images), zeros) + lossD(D_B(fake_B), zeros)\n",
        "        else:\n",
        "            lossD_B = lossD(D_B(images), zeros)\n",
        "        if idtLoss:\n",
        "            lossG_A = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images) + lossCyc(idt_A, images))\n",
        "        else:\n",
        "            lossG_A = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        lossG_B = lossD(D_B(fake_B), ones) + lossC(C_B(fake_B), label) + hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        \n",
        "        # Compute accuracy\n",
        "        correctC_A += (torch.max(C_B(images), 1)[1] == label).sum()\n",
        "        totalC_A += labels.size(0)\n",
        "        correctD_A += (torch.max(D_A(images), 1)[1] == zeros[0].long()).sum()\n",
        "        totalD_A += hyp_miniBatchSize\n",
        "        correctD_B += (torch.max(D_B(images), 1)[1] == zeros[0].long()).sum()\n",
        "        totalD_B += hyp_miniBatchSize\n",
        "        if voiceShield:\n",
        "            correctD_B += (torch.max(D_B(fake_B), 1)[1] == zeros[0].long()).sum()\n",
        "            totalD_B += hyp_minibatchsize\n",
        "                                                                                              \n",
        "        # Output results\n",
        "        if (i + 1) % len(testA) == 0:\n",
        "            print('Epoch [%d/%d], Step[%d/%d] (Test set A): LossC_A: %.6f, LossD_A: %.6f, LossD_B: %.6f, LossG_A: %.6f, LossG_B: %.6f, '\n",
        "             %(epoch + 1, num_epochs, i + 1, len(testA)//hyp_miniBatchSize, lossC_A.item(), lossD_A.item(), lossD_B.item(), lossG_A.item(), lossG_B.item()))\n",
        "            print('Accuracy: AccC_A %.6f, AccD_A: %.6f, AccD_B: %.6f' %(100 * correctC_A / totalC_A, 100 * correctD_A / totalD_A, 100 * correctD_B / totalD_B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBppv1Oxnmdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Method for testing step on speaker B data"
      ]
    },
    {
      "metadata": {
        "id": "WauunAmMnmdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def testEpochB(epoch):\n",
        "    correctD_A = 0\n",
        "    totalD_A = 0\n",
        "    correctD_B = 0\n",
        "    totalD_B = 0\n",
        "    correctC_B = 0\n",
        "    totalC_B = 0\n",
        "    for i, (images, labels) in enumerate(testloaderB):\n",
        "        # Transfer data to GPU\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        label = torch.max(labels, 1)[1]\n",
        "        \n",
        "        # Pass through generators\n",
        "        fake_A = G_A(images)\n",
        "        idt_B = G_B(images)\n",
        "        cyc_A = G_A(G_B(images))\n",
        "        cyc_B = G_B(G_A(images))\n",
        "        \n",
        "        # Compute losses\n",
        "        lossC_B = lossC(C_B(images), label)\n",
        "        lossD_B = lossD(D_B(images), ones)\n",
        "        if voiceShield:\n",
        "            lossD_A = lossD(D_A(images), zeros) + lossD(D_A(fake_A), zeros)\n",
        "        else:\n",
        "            lossD_A = lossD(D_A(images), zeros)\n",
        "        if idtLoss:\n",
        "            lossG_B = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images) + lossCyc(idt_B, images))\n",
        "        else:\n",
        "            lossG_B = hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        lossG_A = lossD(D_A(fake_A), ones) + lossC(C_A(fake_A), label) + hyp_lambda * (lossCyc(cyc_A, images) + lossCyc(cyc_B, images))\n",
        "        \n",
        "        # Compute accuracy\n",
        "        correctC_B += (torch.max(C_B(images), 1)[1] == label).sum()\n",
        "        totalC_B += labels.size(0)\n",
        "        correctD_B += (torch.max(D_B(images), 1)[1] == zeros[0].long()).sum()\n",
        "        totalD_B += hyp_miniBatchSize\n",
        "        correctD_A += (torch.max(D_A(images), 1)[1] == zeros[0].long()).sum()\n",
        "        totalD_A += hyp_miniBatchSize\n",
        "        if voiceShield:\n",
        "            correctD_A += (torch.max(D_A(fake_A), 1)[1] == zeros[0].long()).sum()\n",
        "            totalD_A += hyp_minibatchsize\n",
        "            \n",
        "        # Output results\n",
        "        if (i + 1) % len(testB) == 0:\n",
        "            print('Epoch [%d/%d], Step[%d/%d] (Test set B): LossC_B: %.6f, LossD_A: %.6f, LossD_B: %.6f, LossG_A: %.6f, LossG_B: %.6f, '\n",
        "             %(epoch + 1, num_epochs, i + 1, len(testB)//hyp_miniBatchSize, lossC_B.item(), lossD_A.item(), lossD_B.item(), lossG_A.item(), lossG_B.item()))\n",
        "            print('Accuracy: AccC_B %.6f, AccD_A: %.6f, AccD_B: %.6f' %(100 * correctC_B / totalC_B, 100 * correctD_A / totalD_A, 100 * correctD_B / totalD_B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sTgF012anmdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Do the actual training"
      ]
    },
    {
      "metadata": {
        "id": "eSzNExrbnmdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    trainEpochA(epoch)\n",
        "    trainEpochB(epoch)\n",
        "    testEpochA(epoch)\n",
        "    testEpochB(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmuqzTbInmdy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results in 'pickles' (files of model parameters)"
      ]
    },
    {
      "metadata": {
        "id": "XiPUqiednmdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MR43ClEnmd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(G_A.state_dict(), \"Models/v3/G_A.pkl\")\n",
        "torch.save(G_B.state_dict(), \"Models/v3/G_B.pkl\")\n",
        "torch.save(D_A.state_dict(), \"Models/v3/D_A.pkl\")\n",
        "torch.save(D_B.state_dict(), \"Models/v3/D_B.pkl\")\n",
        "torch.save(C_A.state_dict(), \"Models/v3/C_A.pkl\")\n",
        "torch.save(C_B.state_dict(), \"Models/v3/C_B.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}